{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and Analyzing 'Pocketed' Articles (https://getpocket.com/)\n",
    "<br>\n",
    "\n",
    "I wrote a script that works with the https://getpocket.com/developer/ \"Retrieve\" API. This script writes out four files called <b>pocket_data_raw.json</b>, <b>pocket_data_raw.pkl</b>, <b>pocket_data.pkl</b>, and <b>pocket_links.pkl</b>. Here is the script documentation:  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run:    python pocket_onboarding.py\n",
      "\n",
      "Input:  Https://getpocket.com account credentials\n",
      "\n",
      "Output: Three DataFrames stored as pocket_data_raw.pkl, pocket_data.pkl, and pocket_links.pkl. \n",
      "        One JSON file stored as pocket_data_raw.json\n",
      "        \n",
      "        1) pocket_data_raw.pkl contains columns of meta data described on\n",
      "           https://getpocket.com/developer/docs/v3/retrieve as well as 'article_text' \n",
      "           which is the body of text extracted using beautifulsoup/requests on 'resolved_url'\n",
      "\n",
      "        2) pocket_data.pkl is a cleaned up version of pocket_data_raw.pkl. See below (def cleanData)\n",
      "           for the full list of cleaning steps that were taken, but for example this includes\n",
      "           eliminating null values from important fields and making assumptions about 'article_text'\n",
      "           word counts. \n",
      "\n",
      "        3) pocket_links.pkl is a two column data frame that maps (many-to-many) 'resolved_url' to\n",
      "           links found while scraping 'resolved_url'. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pocket_onboarding\n",
    "print pocket_onboarding.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## pocket_data_raw.json\n",
    "This file contains the raw data returned from the aforementioned \"Retrieve\" API which is described <a href=\"https://getpocket.com/developer/docs/v3/retrieve\">here</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Articles:  874\n",
      "\n",
      "-- Sample Article --\n",
      "\n",
      "{u'excerpt': u\"One reason programmers dislike meetings so much is that they're on a different type of schedule from other people. Meetings cost them more.  There are two types of schedule, which I'll call the manager's schedule and the maker's schedule. The manager's schedule is for bosses.\",\n",
      " u'favorite': u'0',\n",
      " u'given_title': u'http://www.paulgraham.com/makersschedule.html',\n",
      " u'given_url': u'http://www.paulgraham.com/makersschedule.html',\n",
      " u'has_image': u'0',\n",
      " u'has_video': u'0',\n",
      " u'is_article': u'1',\n",
      " u'is_index': u'0',\n",
      " u'item_id': u'14878635',\n",
      " u'resolved_id': u'14878635',\n",
      " u'resolved_title': u\"Maker's Schedule, Manager's Schedule\",\n",
      " u'resolved_url': u'http://www.paulgraham.com/makersschedule.html',\n",
      " u'sort_id': 256,\n",
      " u'status': u'1',\n",
      " u'tags': {u'management': {u'item_id': u'14878635', u'tag': u'management'},\n",
      "           u'workplace': {u'item_id': u'14878635', u'tag': u'workplace'}},\n",
      " u'time_added': u'1447636682',\n",
      " u'time_favorited': u'0',\n",
      " u'time_read': u'1447788612',\n",
      " u'time_updated': u'1447788777',\n",
      " u'word_count': u'1128'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "with open('pocket_data_raw.json', 'rb') as fp:\n",
    "    pocket_data_raw = json.load(fp)\n",
    "    print \n",
    "    print \"Number of Articles: \", len(pocket_data_raw['list'].keys())\n",
    "    print \n",
    "    print \"-- Sample Article --\"\n",
    "    print \n",
    "    it = pocket_data_raw['list'].itervalues()\n",
    "    it.next(); it.next()\n",
    "    pprint.pprint(it.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## pocket_data_raw.pkl \n",
    "The next step was to use beautifulsoup and requests to scrap and extract <b>'article_text'</b> from <b>'resolved_url'</b>. Once that is done, I converted the JSON data to a pandas DataFrame and stored it to disk using the <a href=\"https://docs.python.org/2/library/pickle.html\">pickle</a> module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data:  (873, 25)\n",
      "\n",
      "-- Sample Article --\n",
      "\n",
      "article_text      want to start a startup get funded by y combin...\n",
      "authors                                                         NaN\n",
      "excerpt           One reason programmers dislike meetings so muc...\n",
      "favorite                                                          0\n",
      "given_title           http://www.paulgraham.com/makersschedule.html\n",
      "given_url             http://www.paulgraham.com/makersschedule.html\n",
      "has_image                                                         0\n",
      "has_video                                                         0\n",
      "image                                                           NaN\n",
      "images                                                          NaN\n",
      "is_article                                                        1\n",
      "is_index                                                          0\n",
      "item_id                                                    14878635\n",
      "resolved_id                                                14878635\n",
      "resolved_title                 Maker's Schedule, Manager's Schedule\n",
      "resolved_url          http://www.paulgraham.com/makersschedule.html\n",
      "sort_id                                                         255\n",
      "status                                                            1\n",
      "tags              {u'management': {u'item_id': u'14878635', u'ta...\n",
      "time_added                                               1447636682\n",
      "time_favorited                                                    0\n",
      "time_read                                                1447788612\n",
      "time_updated                                             1447788777\n",
      "videos                                                          NaN\n",
      "word_count                                                     1128\n",
      "Name: 3, dtype: object\n",
      "\n",
      "-- Sample 'article_text' --\n",
      "\n",
      "want to start a startup get funded by y combinator july one reason programmers dislike meetings so much is that theyre on a different type of schedule from other people meetings cost them morethere are two types of schedule which ill call the managers schedule and the makers schedule the managers schedule is for bosses its embodied in the traditional appointment book with each day cut into one hour intervals you can block off several hours for a single task if you need to but by default you chan ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# make sure we display all the columns\n",
    "pd.set_option('display.max_columns', 25)\n",
    "df = pd.read_pickle('pocket_data_raw.pkl')\n",
    "print \"Shape of Data: \", df.shape\n",
    "print \n",
    "print \"-- Sample Article --\"\n",
    "print\n",
    "print df.iloc[3]\n",
    "print\n",
    "print \"-- Sample 'article_text' --\"\n",
    "print \n",
    "print df.iloc[3].article_text[:500], '...'\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## pocket_data.pkl \n",
    "This file is a cleaned up version of <b>pocket_data_raw.pkl</b>. Here I've restricted the 25 columns to just the columns I'm interested in using, defined a couple new columns, excluded rows with strange 'null' values that I encountered while examining the data, and excluded rows that didn't live up to the word count requirements I'm enforcing. \n",
    "\n",
    "In a nutshell, here are the cleaning steps I took:\n",
    "```\n",
    "  # clean all missing article_text - not sure why this happens\n",
    "  df = df[pd.notnull(df['article_text'])]\n",
    "  \n",
    "  # translate binary fields to true/false\n",
    "  df['is_archived'] = df.status.map(lambda x: int(x) !=0)\n",
    "  \n",
    "  # define actual word count\n",
    "  df['actual_word_count'] = df.article_text.map(lambda x: len(x.split()))\n",
    "\n",
    "  # select only the columns we are interested in using\n",
    "  df = df[['resolved_id', 'word_count', 'actual_word_count', 'resolved_title', \n",
    "    'resolved_url', 'article_text', 'is_archived', 'excerpt', 'tags']]\n",
    "\n",
    "  # TfidfVectorizer, which will most likely be used to featurize, \n",
    "  # doesn't work well on smaller samples. Also, pages that depend\n",
    "  # mostly on javascript can have zero words in either column.\n",
    "  df = df[df.word_count.astype(int) > 100]\n",
    "  df = df[df.actual_word_count.astype(int) > 100]    \n",
    "\n",
    "  # find the percent difference between the two counts\n",
    "  percent_diffs = np.abs( df.actual_word_count.astype(int) - df.word_count.astype(int) )\n",
    "  percent_diffs = ( percent_diffs * 100 ) / df.word_count.astype(int)\n",
    "  df['percent_diffs'] = percent_diffs\n",
    "\n",
    "  # exclude anything greater than 300% difference in word count\n",
    "  df = df[df.percent_diffs < 300]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data:  (638, 10)\n",
      "\n",
      "-- Sample Article --\n",
      "\n",
      "resolved_id                                                   14878635\n",
      "word_count                                                        1128\n",
      "actual_word_count                                                 1134\n",
      "resolved_title                    Maker's Schedule, Manager's Schedule\n",
      "resolved_url             http://www.paulgraham.com/makersschedule.html\n",
      "article_text         want to start a startup get funded by y combin...\n",
      "is_archived                                                       True\n",
      "excerpt              One reason programmers dislike meetings so muc...\n",
      "tags                 {u'management': {u'item_id': u'14878635', u'ta...\n",
      "percent_diffs                                                 0.531915\n",
      "Name: 3, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# make sure we display all the columns\n",
    "pd.set_option('display.max_columns', 25)\n",
    "df = pd.read_pickle('pocket_data.pkl')\n",
    "print \"Shape of Data: \", df.shape\n",
    "print \n",
    "print \"-- Sample Article --\"\n",
    "print\n",
    "print df.iloc[3]\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Definitions\n",
    "* **resolved_id** - A unique identifier similar to the item_id but is unique to the actual url of the saved item. The resolved_id identifies unique urls. For example a direct link to a New York Times article and a link that redirects (ex a shortened bit.ly url) to the same article will share the same resolved_id. If this value is 0, it means that Pocket has not processed the item. Normally this happens within seconds but is possible you may request the item before it has been resolved.\n",
    "* **word_count** - How many words are in the article (determined by pocket)\n",
    "* **actual_word_count** - How many words are in the article (determined after scraping + cleaning)\n",
    "* **resolved_title** - The title that Pocket found for the item when it was parsed\n",
    "* **resolved_url** - The final url of the item. For example if the item was a shortened bit.ly link, this will be the actual article the url linked to.\n",
    "* **article_text** - The text that was scraped + cleaned\n",
    "* **is_archived** - True/False (Have I read the article and archived it?)\n",
    "* **excerpt** - The first few lines of the item (articles only)\n",
    "* **tags** - A JSON object of the user tags associated with the item\n",
    "* **percent_diffs** - Difference betwween word_count and actual_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## pocket_links.pkl \n",
    "While using beautifulsoup to extract **'article_text'**, I also scraped the links found in each article and dumped them into a dataframe for later. It is my hope to build a recommendation system using these links as inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42301, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>found_link</th>\n",
       "      <th>resolved_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://time.com/3928685/nepal-earthquake-recov...</td>\n",
       "      <td>909801869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://cgi.timeinc.net/cgi-bin/mail/dnp/terms_...</td>\n",
       "      <td>909801869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://time.com/us/</td>\n",
       "      <td>909801869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://secure.customersvc.com/servlet/Show?WE...</td>\n",
       "      <td>909801869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pinterest.com/timemagazine/</td>\n",
       "      <td>909801869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          found_link resolved_id\n",
       "0  http://time.com/3928685/nepal-earthquake-recov...   909801869\n",
       "1  http://cgi.timeinc.net/cgi-bin/mail/dnp/terms_...   909801869\n",
       "2                                http://time.com/us/   909801869\n",
       "3  https://secure.customersvc.com/servlet/Show?WE...   909801869\n",
       "4            https://www.pinterest.com/timemagazine/   909801869"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_pickle('pocket_links.pkl')\n",
    "print links.shape\n",
    "links.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332012769    589\n",
      "322918430    465\n",
      "941408661    431\n",
      "915810002    420\n",
      "624520141    391\n",
      "Name: resolved_id, dtype: int64\n",
      "827\n"
     ]
    }
   ],
   "source": [
    "print links.resolved_id.value_counts().head()\n",
    "print links.resolved_id.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
